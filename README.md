# Aspect-Based Twitter Sentiment Analysis

## ğŸ“Œ Project Overview

A **lightweight NLP application** that analyzes sentiment of tweets at both overall and aspect levels. Users input any text, and the system:
1. Cleans the text
2. Extracts key aspects (nouns)
3. Analyzes sentiment (POSITIVE/NEGATIVE)
4. Displays results via interactive UI

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Input â”‚ (Text typed in Streamlit)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preprocessing   â”‚ (Clean text: lowercase, remove URLs, special chars)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Aspect Extraction    â”‚ (Extract nouns using spaCy: flight, seats, crew)
â”‚ + Filtering          â”‚ (Remove useless words: this, it, that)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Local Context Extraction     â”‚ (Split by "but", "and" to isolate clause)
â”‚ (Clause-Based)               â”‚ (Find clause containing the aspect)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Clause-Based         â”‚ (BERT analyzes aspect IN ITS CLAUSE only)
â”‚ Sentiment Analysis   â”‚ (Ignores unrelated clauses)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Display Results      â”‚ (Show overall + aspect sentiments)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Clause-Based Analysis?

**Problem with Full-Sentence Context:**
```
Input: "food quality is great but delivery time is horrible"

Model Analysis:
- Aspect "food quality" with full sentence
- Model sees BOTH positive ("great") and negative ("horrible") 
- Might assign wrong sentiment due to dominance of last phrase
```

**Solution with Clause-Based Context:**
```
Input: "food quality is great but delivery time is horrible"

Smart Extraction:
- Aspect "food quality" â†’ Found in "food quality is great" clause only
- Aspect "delivery time" â†’ Found in "delivery time is horrible" clause only
- Each aspect analyzed IN ITS OWN CLAUSE only
- Result: Correct sentiments for both aspects
```

**Technical Name:** Rule-Enhanced Contextual ABSA (Aspect-Based Sentiment Analysis)

### Data Flow Example

**Input:** `"The food quality is great but delivery time is horrible"`

**Processing:**
```
1. CLEAN: "the food quality is great but delivery time is horrible"

2. EXTRACT ASPECTS: [food quality, delivery time]
   (Filtered out useless words)

3. OVERALL SENTIMENT: 
   Input â†’ BERT â†’ MIXED (Contains both positive and negative)

4. CLAUSE-BASED CONTEXT EXTRACTION:
   - "food quality" found in: "the food quality is great"
   - "delivery time" found in: "delivery time is horrible"

5. ASPECT SENTIMENT (Clause-Isolated):
   - "food quality" clause: "the food quality is great" â†’ POSITIVE âœ“
   - "delivery time" clause: "delivery time is horrible" â†’ NEGATIVE âœ“

6. DISPLAY: Show both overall and aspect-level sentiments
```

**Why This Works:**
- Each aspect analyzed in its own clause, not influenced by other clauses
- No sentence-level dominance effects
- Aspect sentiment reflects ONLY relevant context

---

## ğŸ“‚ Project Structure

```
aspect_sentiment_project/
â”œâ”€â”€ app.py                      # Streamlit UI & main orchestration
â”œâ”€â”€ preprocessing.py            # Text cleaning (regex-based)
â”œâ”€â”€ aspect_extractor.py         # Noun extraction (spaCy NLP)
â”œâ”€â”€ sentiment_model.py          # BERT sentiment classification
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

---

## ğŸ“‹ File Responsibilities

| File | Purpose | Technology |
|------|---------|-----------|
| `app.py` | Main UI & pipeline orchestration | Streamlit |
| `preprocessing.py` | Text cleaning (lowercase, remove URLs/special chars) | RegEx |
| `aspect_extractor.py` | Extract noun phrases (aspects) | spaCy NLP |
| `sentiment_model.py` | Classify sentiment POSITIVE/NEGATIVE | BERT (Transformers) |

---

## ğŸ§  Model Details

### Pre-trained Model Used
- **Model:** `distilbert-base-uncased-finetuned-sst-2-english`
- **Source:** Hugging Face
- **Training Data:** SST-2 dataset (movie reviews, tweets)
- **Classes:** POSITIVE, NEGATIVE
- **Note:** NO training needed - model is ready to use

### Why We Use This Model
âœ… Already trained on millions of tweets & reviews  
âœ… No training time required  
âœ… High accuracy  
âœ… Lightweight & fast  
âœ… Free & open-source  

### How the Model Works
- **NO training needed** - model is pre-trained and ready to use
- Analyzes user text input in real-time
- Works entirely on the text you type (no dataset required)

---

## ğŸš€ How to Run

### Prerequisites
- Python 3.8+ (tested on Python 3.12)
- pip package manager

### Installation

**Option 1: Using Virtual Environment (Recommended)**

```bash
# Navigate to project
cd aspect_sentiment_project

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Download spaCy language model
python -m spacy download en_core_web_sm
```

**Option 2: Global Installation (Current Setup)**

```bash
# Navigate to project
cd aspect_sentiment_project

# Install dependencies globally
pip install -r requirements.txt

# Download spaCy language model
python -m spacy download en_core_web_sm
```

**Note:** Dependencies are currently installed globally. For better project isolation, consider using a virtual environment.

### Run the App

```bash
streamlit run app.py
```

Access at: `http://localhost:8501`

---

## ğŸ“¸ Demo Screenshot

![Application Demo](screenshots/demo.png)

**Example Analysis:**
- **Input:** "food quality is great but delivery time is horrible"
- **Overall Sentiment:** NEGATIVE
- **Aspect-Level Results:**
  - `food quality` â†’ POSITIVE _(food quality is great)_
  - `delivery time` â†’ NEGATIVE _(delivery time is horrible)_

The clause-based context extraction correctly separates sentiments for different aspects!

---

## ğŸ“ How to Use

1. **Open the Streamlit app** (runs on localhost:8501)
2. **Type a tweet or sentence** in the text area
3. **Click "Analyze"** button
4. **See results:**
   - Cleaned text
   - Overall sentiment (POSITIVE/NEGATIVE)
   - Aspect-level sentiment breakdown

### Example Test Inputs

**Negative sentiment:**
```
I hate this airline the flight was terrible and the seats are so uncomfortable
```
Expected: Overall NEGATIVE, Aspects (airline, flight, seats) â†’ NEGATIVE

**Positive sentiment:**
```
I love the new seats the crew was amazing and the service was excellent
```
Expected: Overall POSITIVE, Aspects (seats, crew, service) â†’ POSITIVE

**Mixed sentiment:**
```
Good food but terrible seats and bad cabin crew
```
Expected: Overall MIXED, Aspects vary by word association

---

### Architecture Explanation
> "The pipeline has six main stages: First, text preprocessing removes noise. Second, aspect extraction identifies important entities using spaCy. Third, aspect filtering removes meaningless words. Fourth, clause-based context extraction splits sentences by connectors to isolate aspect-relevant context. Fifth, sentiment analysis applies BERT to the isolated clause. Sixth, results are displayed. The threelayer hierarchy (Sentence â†’ Clause â†’ Aspect â†’ Sentiment) ensures intelligent context isolation."

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Frontend** | Streamlit | Interactive web UI |
| **NLP - Aspect Extraction** | spaCy | Extract noun phrases |
| **NLP - Sentiment** | Transformers (BERT) | Classify sentiment |
| **Python Version** | 3.8+ | Core language |

---

## ğŸ“Š Model Performance

- **Accuracy on SST-2:** ~91%
- **Inference Time:** ~200-500ms per analysis
- **Model Size:** ~268MB (downloaded automatically)

---

## âœ¨ Features Implemented

âœ… Clean, intuitive Streamlit UI  
âœ… Text preprocessing (lowercase, remove noise)  
âœ… Aspect extraction using spaCy NLP  
âœ… Overall sentiment classification  
âœ… Aspect-level sentiment analysis  
âœ… Error handling & validation  
âœ… Real-time results display  

---

## ğŸ¯ Why This Design

1. **Simple:** No microservices, no APIs, no complexity
2. **Real:** Uses actual NLP libraries (spaCy, BERT)
3. **Scalable:** Can process any text input
4. **Maintainable:** Clean modular code structure
5. **Resume-Ready:** Shows practical ML skills

---

## ğŸ”§ Implementation Improvements

### Improvement 1: Clause-Based Context Extraction

**Problem:** Full-sentence context can be misleading when sentence has multiple sentiments.

Example:
```
"food quality is great but delivery time is horrible"
```

- If we analyze "food quality" with full sentence context
- Model might be confused by "horrible" at the end
- Wrong sentiment assignment for "food quality"

**Solution:** Extract only the clause containing the aspect.

**How it works:**
1. Split sentence by "but", "and" (connectors that indicate separate clauses)
2. Find which clause contains the aspect
3. Run sentiment analysis on ONLY that clause

**Code Implementation:**
```python
def get_local_context(aspect, text):
    # Split by 'but' (contrast indicator)
    parts = text.split(" but ")
    for part in parts:
        if aspect.lower() in part.lower():
            return part.strip()
    
    # Split by 'and'
    parts = text.split(" and ")
    for part in parts:
        if aspect.lower() in part.lower():
            return part.strip()
    
    return text  # Fallback
```

**Result:**

| Aspect | Extracted Clause | Sentiment |
|--------|------------------|-----------|
| food quality | "food quality is great" | POSITIVE âœ“ |
| delivery time | "delivery time is horrible" | NEGATIVE âœ“ |

**Technical Name:** Clause-Based Contextual ABSA

---

### Improvement 2: Filter Useless Aspects

**Problem:** spaCy extracts garbage aspects like "this", "it", "that"

**Solution:** Filter out short words and common pronouns

**Code Change:**
```python
# aspect_extractor.py
if len(chunk.text) > 2 and chunk.text.lower() not in ["this", "it", "that", "what", "which", "who", "one"]:
    aspects.append(chunk.text)
```

**Result:** Only meaningful aspects are extracted and displayed.

---

### Three-Layer Architecture

```
Sentence (Full text)
    â†“
Clause (Aspect-specific context)
    â†“
Aspect (The noun/entity)
    â†“
Sentiment (POSITIVE/NEGATIVE)
```

---

## ğŸ”§ Limitations & Future Improvements

### Limitations Addressed âœ…
- âœ… Aspects analyzed with clause-based context (not isolated words)
- âœ… Filtering removes meaningless pronouns (this, it, that)
- âœ… Clause extraction prevents cross-clause sentiment confusion
- âœ… Rule-enhanced contextual ABSA approach implemented

### Remaining Limitations
- Limited to POSITIVE/NEGATIVE (no neutral class)
- Single-language (English only)
- Clause extraction works for "but"/"and" connectors (not advanced linguistic parsing)
- Rule-based approach (vs. advanced fine-tuned models)

### Possible Future Improvements
- Add neutral sentiment class  
- Support more clause connectors (however, although, despite, etc.)
- Fine-tune BERT on custom aspect-sentiment dataset
- Multi-language support
- Add confidence scores to predictions
- Aspect categorization (service, food, price, delivery, etc.)
- Sentiment trend analysis for multiple tweets

---

## ğŸ“š Dependencies

See `requirements.txt` for complete list:
- streamlit
- transformers
- spacy
- torch

---

## ğŸ‘¨â€ğŸ’» Developer Notes

- Model downloads automatically on first run
- spaCy model must be downloaded separately
- All computations happen locally (no API calls)
- No training required - pre-trained model used

---

## ğŸ“„ License

Open source - free to use and modify

